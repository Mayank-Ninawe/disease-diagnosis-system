{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54dcb2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "Original dataset shape: (4920, 134)\n",
      "Columns: 134\n",
      "\n",
      "============================================================\n",
      "DATA CLEANING\n",
      "============================================================\n",
      "\n",
      "1. Checking for missing values...\n",
      "   Total missing values: 4920\n",
      "\n",
      "   Missing values per column:\n",
      "Unnamed: 133    4920\n",
      "dtype: int64\n",
      "\n",
      "   Filling NaN values with 0...\n",
      "   ✅ Missing values after cleaning: 0\n",
      "\n",
      "2. Checking target column...\n",
      "   ✅ 'prognosis' column found\n",
      "\n",
      "3. Checking for duplicates...\n",
      "   Duplicate rows: 4616\n",
      "   ✅ Removed 4616 duplicate rows\n",
      "\n",
      "4. Separating features and target...\n",
      "   Features shape: (304, 133)\n",
      "   Target shape: (304,)\n",
      "\n",
      "5. Checking data types...\n",
      "   Feature data types:\n",
      "int64      132\n",
      "float64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "6. Converting features to numeric...\n",
      "   ✅ All features converted to numeric\n",
      "   Final feature shape: (304, 133)\n",
      "   ✅ No NaN values in features\n",
      "\n",
      "============================================================\n",
      "ENCODING TARGET\n",
      "============================================================\n",
      "Number of unique diseases: 41\n",
      "Sample diseases: ['Fungal infection' 'Allergy' 'GERD' 'Chronic cholestasis' 'Drug Reaction']\n",
      "✅ Encoded 41 disease classes\n",
      "\n",
      "============================================================\n",
      "SPLITTING DATA\n",
      "============================================================\n",
      "Training set: (243, 133)\n",
      "Testing set: (61, 133)\n",
      "\n",
      "✅ Data preprocessing complete!\n",
      "   Total samples: 304\n",
      "   Features: 133\n",
      "   Diseases: 41\n",
      "   Train size: 243\n",
      "   Test size: 61\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING\n",
      "============================================================\n",
      "\n",
      "1️⃣ Training Random Forest Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Random Forest Accuracy: 96.72%\n",
      "\n",
      "2️⃣ Training Naive Bayes Classifier...\n",
      "   ✅ Naive Bayes Accuracy: 98.36%\n",
      "\n",
      "3️⃣ Training Support Vector Machine...\n",
      "   ✅ SVM Accuracy: 100.00%\n",
      "\n",
      "============================================================\n",
      "ENSEMBLE PREDICTION\n",
      "============================================================\n",
      "✅ Ensemble Accuracy: 100.00%\n",
      "\n",
      "============================================================\n",
      "SAVING MODELS\n",
      "============================================================\n",
      "✅ Random Forest saved\n",
      "✅ Naive Bayes saved\n",
      "✅ SVM saved\n",
      "✅ Label Encoder saved\n",
      "✅ Feature names saved (133 features)\n",
      "\n",
      "============================================================\n",
      "🎉 TRAINING COMPLETE - FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset Statistics:\n",
      "  • Total Records: 304\n",
      "  • Features: 133 symptoms\n",
      "  • Diseases: 41 classes\n",
      "  • Training Samples: 243\n",
      "  • Testing Samples: 61\n",
      "\n",
      "Model Performance:\n",
      "  🌲 Random Forest:  96.72%\n",
      "  📊 Naive Bayes:    98.36%\n",
      "  🎯 SVM:            100.00%\n",
      "  🏆 Ensemble:       100.00%\n",
      "\n",
      "Models Saved:\n",
      "  ✅ rf_model.pkl\n",
      "  ✅ nb_model.pkl\n",
      "  ✅ svm_model.pkl\n",
      "  ✅ label_encoder.pkl\n",
      "  ✅ feature_names.pkl\n",
      "\n",
      "Status: Ready for deployment! 🚀\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TESTING SAMPLE PREDICTION\n",
      "============================================================\n",
      "Sample symptoms: 11.0 active symptoms\n",
      "\n",
      "True disease: Hepatitis B\n",
      "\n",
      "Predictions:\n",
      "  Random Forest: Hepatitis B\n",
      "  Naive Bayes:   Hepatitis B\n",
      "  SVM:           Hepatitis B\n",
      "\n",
      "🏆 Final Prediction: Hepatitis B\n",
      "✅ Prediction CORRECT!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model Training - WITH DATA CLEANING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('../data/Training.csv')\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# DATA CLEANING - STEP BY STEP\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n1. Checking for missing values...\")\n",
    "missing_before = df.isnull().sum().sum()\n",
    "print(f\"   Total missing values: {missing_before}\")\n",
    "\n",
    "if missing_before > 0:\n",
    "    print(\"\\n   Missing values per column:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "    \n",
    "    # Fill NaN with 0 (assuming missing symptoms = not present)\n",
    "    print(\"\\n   Filling NaN values with 0...\")\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    missing_after = df.isnull().sum().sum()\n",
    "    print(f\"   ✅ Missing values after cleaning: {missing_after}\")\n",
    "else:\n",
    "    print(\"   ✅ No missing values found!\")\n",
    "\n",
    "# Check if 'prognosis' column exists\n",
    "print(\"\\n2. Checking target column...\")\n",
    "if 'prognosis' in df.columns:\n",
    "    print(\"   ✅ 'prognosis' column found\")\n",
    "else:\n",
    "    print(\"   ❌ 'prognosis' column NOT found!\")\n",
    "    print(f\"   Available columns: {df.columns.tolist()}\")\n",
    "    raise ValueError(\"Target column 'prognosis' not found in dataset!\")\n",
    "\n",
    "# Remove any duplicate rows\n",
    "print(\"\\n3. Checking for duplicates...\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"   Duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"   ✅ Removed {duplicates} duplicate rows\")\n",
    "\n",
    "# Separate features and target\n",
    "print(\"\\n4. Separating features and target...\")\n",
    "X = df.drop('prognosis', axis=1)\n",
    "y = df['prognosis']\n",
    "\n",
    "print(f\"   Features shape: {X.shape}\")\n",
    "print(f\"   Target shape: {y.shape}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n5. Checking data types...\")\n",
    "print(f\"   Feature data types:\\n{X.dtypes.value_counts()}\")\n",
    "\n",
    "# Convert all features to numeric (just in case)\n",
    "print(\"\\n6. Converting features to numeric...\")\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Fill any NaN that appeared during conversion\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"   ✅ All features converted to numeric\")\n",
    "print(f\"   Final feature shape: {X.shape}\")\n",
    "\n",
    "# Verify no NaN values remain\n",
    "assert X.isnull().sum().sum() == 0, \"❌ NaN values still present!\"\n",
    "print(\"   ✅ No NaN values in features\")\n",
    "\n",
    "# ENCODE TARGET\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENCODING TARGET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Number of unique diseases: {y.nunique()}\")\n",
    "print(f\"Sample diseases: {y.unique()[:5]}\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"✅ Encoded {len(le.classes_)} disease classes\")\n",
    "\n",
    "# TRAIN-TEST SPLIT\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPLITTING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\n✅ Data preprocessing complete!\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Features: {X.shape[1]}\")\n",
    "print(f\"   Diseases: {len(le.classes_)}\")\n",
    "print(f\"   Train size: {len(X_train)}\")\n",
    "print(f\"   Test size: {len(X_test)}\")\n",
    "\n",
    "# MODEL TRAINING\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Random Forest\n",
    "print(\"\\n1️⃣ Training Random Forest Classifier...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "rf_acc = rf.score(X_test, y_test)\n",
    "print(f\"   ✅ Random Forest Accuracy: {rf_acc*100:.2f}%\")\n",
    "\n",
    "# 2. Naive Bayes\n",
    "print(\"\\n2️⃣ Training Naive Bayes Classifier...\")\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_acc = nb.score(X_test, y_test)\n",
    "print(f\"   ✅ Naive Bayes Accuracy: {nb_acc*100:.2f}%\")\n",
    "\n",
    "# 3. SVM\n",
    "print(\"\\n3️⃣ Training Support Vector Machine...\")\n",
    "svm = SVC(kernel='linear', random_state=42, C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_acc = svm.score(X_test, y_test)\n",
    "print(f\"   ✅ SVM Accuracy: {svm_acc*100:.2f}%\")\n",
    "\n",
    "# ENSEMBLE EVALUATION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "nb_pred = nb.predict(X_test)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "# Majority voting\n",
    "ensemble_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    votes = [rf_pred[i], nb_pred[i], svm_pred[i]]\n",
    "    final_vote = max(set(votes), key=votes.count)\n",
    "    ensemble_pred.append(final_vote)\n",
    "\n",
    "ensemble_pred = np.array(ensemble_pred)\n",
    "ensemble_acc = (ensemble_pred == y_test).sum() / len(y_test)\n",
    "print(f\"✅ Ensemble Accuracy: {ensemble_acc*100:.2f}%\")\n",
    "\n",
    "# SAVE MODELS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_dir = '../models/'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save all models\n",
    "pickle.dump(rf, open(os.path.join(model_dir, 'rf_model.pkl'), 'wb'))\n",
    "print(\"✅ Random Forest saved\")\n",
    "\n",
    "pickle.dump(nb, open(os.path.join(model_dir, 'nb_model.pkl'), 'wb'))\n",
    "print(\"✅ Naive Bayes saved\")\n",
    "\n",
    "pickle.dump(svm, open(os.path.join(model_dir, 'svm_model.pkl'), 'wb'))\n",
    "print(\"✅ SVM saved\")\n",
    "\n",
    "pickle.dump(le, open(os.path.join(model_dir, 'label_encoder.pkl'), 'wb'))\n",
    "print(\"✅ Label Encoder saved\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names = X.columns.tolist()\n",
    "pickle.dump(feature_names, open(os.path.join(model_dir, 'feature_names.pkl'), 'wb'))\n",
    "print(f\"✅ Feature names saved ({len(feature_names)} features)\")\n",
    "\n",
    "# FINAL SUMMARY\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 TRAINING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Dataset Statistics:\n",
    "  • Total Records: {len(df)}\n",
    "  • Features: {X.shape[1]} symptoms\n",
    "  • Diseases: {len(le.classes_)} classes\n",
    "  • Training Samples: {len(X_train)}\n",
    "  • Testing Samples: {len(X_test)}\n",
    "\n",
    "Model Performance:\n",
    "  🌲 Random Forest:  {rf_acc*100:.2f}%\n",
    "  📊 Naive Bayes:    {nb_acc*100:.2f}%\n",
    "  🎯 SVM:            {svm_acc*100:.2f}%\n",
    "  🏆 Ensemble:       {ensemble_acc*100:.2f}%\n",
    "\n",
    "Models Saved:\n",
    "  ✅ rf_model.pkl\n",
    "  ✅ nb_model.pkl\n",
    "  ✅ svm_model.pkl\n",
    "  ✅ label_encoder.pkl\n",
    "  ✅ feature_names.pkl\n",
    "\n",
    "Status: Ready for deployment! 🚀\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test prediction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING SAMPLE PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get first test sample\n",
    "sample = X_test.iloc[0].values.reshape(1, -1)\n",
    "sample_true = y_test[0]\n",
    "\n",
    "# Predict\n",
    "sample_rf = rf.predict(sample)[0]\n",
    "sample_nb = nb.predict(sample)[0]\n",
    "sample_svm = svm.predict(sample)[0]\n",
    "\n",
    "print(f\"Sample symptoms: {X_test.iloc[0].sum()} active symptoms\")\n",
    "print(f\"\\nTrue disease: {le.inverse_transform([sample_true])[0]}\")\n",
    "print(f\"\\nPredictions:\")\n",
    "print(f\"  Random Forest: {le.inverse_transform([sample_rf])[0]}\")\n",
    "print(f\"  Naive Bayes:   {le.inverse_transform([sample_nb])[0]}\")\n",
    "print(f\"  SVM:           {le.inverse_transform([sample_svm])[0]}\")\n",
    "\n",
    "votes = [sample_rf, sample_nb, sample_svm]\n",
    "final = max(set(votes), key=votes.count)\n",
    "print(f\"\\n🏆 Final Prediction: {le.inverse_transform([final])[0]}\")\n",
    "\n",
    "if final == sample_true:\n",
    "    print(\"✅ Prediction CORRECT!\")\n",
    "else:\n",
    "    print(\"❌ Prediction INCORRECT\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
